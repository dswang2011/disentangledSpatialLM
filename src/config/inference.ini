
[COMMON]
seed =  88

# 1. set dataset, model
# dataset: funsd, cord, rvl, sorie, cdip, docvqa_ocr
dataset_name = docvqa_ocr

# layoutlm, spatial_lm, roberta, graph_roberta
network_type = spatial_lm
# output_dir = layoutlmv3-cord

# 2. {mlm, token-classifier, sequence-classifier, docvqa}
task_type = docvqa


inference_only = True

# === negative use all, positive only use subset ======
test_small_samp = -1

# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.
# 2.2 task usage
# graph_feature = True
# graph_vect_path = /home/ubuntu/python_projects/DocGraph4LM/src/tmp_dir/graphsage_docvqa4g_522066/
# BERT sequence can be sub-word sequence;  

# 3. set hyper parameters
batch_size = 3
epochs = 5
lr = 0.0001
patience = 20
dropout = 0.1
max_seq_len = 512

# spatial_attention = True

# hidden_size = 768
# hidden_dim = 100
# hidden_dim_1 = 64
# hidden_dim_2 = 32

# 4. continue train
# continue_train = True
# continue_with_model = /home/ubuntu/air/vrdu/models/csmodel_rvlcdip_initial/

layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.large
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/trained_path/large
checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir/checkpoint-18256
# checkpoint_path = /home/ubuntu/air/vrdu/output/pretrain_rvl/test_base/checkpoint-22485
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir/checkpoint-200
save_model = False
# save_path = tmp_dir/
# other less common parameters 
embedding_trainable = True

# rvl_cdip_ds = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/weighted_rvl1_dataset.hf
# cdip_path = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_cdip_comb_a_7w.hf
cdip_path = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_cdip_comb_d_6.6w.hf
# layoutlm_large = /home/ubuntu/air/vrdu/models/layoutlmv1.large
# layoutlm_large = /home/ubuntu/air/vrdu/models/roberta.base.squad
# layoutlm_dir = /home/ubuntu/resources/layoutlmv3.base
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.docvqa
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.large

funsd_train = /home/ubuntu/air/vrdu/datasets/FUNSD/training_data/
funsd_test = /home/ubuntu/air/vrdu/datasets/FUNSD/testing_data/

cord_train = /home/ubuntu/air/vrdu/datasets/CORD/train/
cord_test = /home/ubuntu/air/vrdu/datasets/CORD/test/

rvl_train = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_train5_dataset.hf
rvl_test = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_test0_dataset.hf

sorie_train = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_train.hf
sorie_test = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_test.hf

docvqa_pickles = /home/ubuntu/air/vrdu/datasets/docvqa/pickles/
filter_no_answer = True

# 88.49 /50; prec 87.37, rec 89.65

# base on funsd: 89.10, rec:89.5, prec: 88.52
# base on funsd + sp: 

# base on cord: 96.37, rec: 96.48, prec: 96.27

# base on sorie: 95.13, rec = 95.50, prec = 94.77
