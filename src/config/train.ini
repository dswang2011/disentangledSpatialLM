
[COMMON]
seed =  88

# embed, attention, both
entangle_mode = attention

visual_embed = False

# 1. set dataset, model
# dataset: funsd, cord, rvl, sorie, docvqa_ocr
dataset_name = funsd

# layoutlm, spatial_lm, roberta, disentlm
network_type = disentlm
# output_dir = layoutlmv3-cord

# 2. {mlm, token-classifier, sequence-classifier, docvqa}
task_type = token-classifier

# === if you use all, set -1, otherwise set a number that you want to test
test_small_samp = -1

# when inference set True, default by False
inference_only = False
# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.
# 2.2 task usage
# graph_feature = True
# graph_vect_path = /home/ubuntu/python_projects/DocGraph4LM/src/tmp_dir/graphsage_docvqa4g_522066/
# BERT sequence can be sub-word sequence;  

# 3. set hyper parameters
batch_size = 4
epochs = 5
lr = 0.0001
patience = 20
dropout = 0.1
max_seq_len = 512

# spatial_attention = False

# hidden_size = 768
# hidden_dim = 100
# hidden_dim_1 = 64
# hidden_dim_2 = 32

# 4. continue train
# continue_train = True
# continue_with_model = /home/ubuntu/air/vrdu/models/csmodel_rvlcdip_initial/

layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.base
checkpoint_path = /home/ubuntu/air/vrdu/models/layoutlmv3.base
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir
# checkpoint_path = /home/ubuntu/air/vrdu/output/pretrain_rvl/test_base/checkpoint-22485
# checkpoint_path = /home/ubuntu/python_projects/Spatial-LM/src/tmp_dir/checkpoint-200
save_model = True
save_path = tmp_dir/b2m_large_rvl
checkpoint_save_path = tmp_dir/

# other less common parameters 
embedding_trainable = True

# rvl_cdip_ds = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/weighted_rvl1_dataset.hf


# layoutlm_large = /home/ubuntu/air/vrdu/models/layoutlmv1.large
# layoutlm_large = /home/ubuntu/air/vrdu/models/roberta.base.squad
# layoutlm_dir = /home/ubuntu/resources/layoutlmv3.base
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.docvqa
# layoutlm_dir = /home/ubuntu/air/vrdu/models/layoutlmv3.large

funsd_train = /home/ubuntu/air/vrdu/datasets/FUNSD/training_data/
funsd_test = /home/ubuntu/air/vrdu/datasets/FUNSD/testing_data/

cord_train = /home/ubuntu/air/vrdu/datasets/CORD/train/
cord_test = /home/ubuntu/air/vrdu/datasets/CORD/test/

rvl_train = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_train0_dataset.hf
rvl_test = /home/ubuntu/air/vrdu/datasets/rvl_HF_datasets/full_rvl_test2_dataset.hf

sorie_train = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_train.hf
sorie_test = /home/ubuntu/air/vrdu/datasets/sorie2019/sorie_test.hf

docvqa_pickles = /home/ubuntu/air/vrdu/datasets/docvqa/pickles/
filter_no_answer = True

# 88.49 /50; prec 87.37, rec 89.65

# base on funsd: 89.10, rec:89.5, prec: 88.52
# base on funsd + sp: 

# base on cord: 96.37, rec: 96.48, prec: 96.27

# base on sorie: 95.13, rec = 95.50, prec = 94.77

# 'eval_precision': 0.9590864278672363, 'eval_recall': 0.9679933665008292, 'eval_f1': 0.9635193133047211, 'eval_accuracy': 0.9890808220905308,

# train: 39289
# train docvqa: 36504

# train rvl, 356725, test on 
# params: 357070969